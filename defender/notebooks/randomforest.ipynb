{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ember\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [20:56<00:00, 179.44s/it]\n"
     ]
    }
   ],
   "source": [
    "ember_folder = \"../../../ember_dataset/\"\n",
    "train_x_ls = []\n",
    "train_y_ls = []\n",
    "test_x_ls = []\n",
    "test_y_ls = []\n",
    "#  Read EMBER dataset\n",
    "extractor = ember.PEFeatureExtractor(2)\n",
    "for root, dir, files in os.walk(ember_folder):\n",
    "    for d in dir:\n",
    "        if d == \"ember\":\n",
    "            continue\n",
    "        dir_path = os.path.join(root, d)\n",
    "        for file in tqdm(os.listdir(dir_path)):\n",
    "            if \"train\" in file:\n",
    "                output_x = train_x_ls\n",
    "                output_y = train_y_ls\n",
    "            else:\n",
    "                output_x = test_x_ls\n",
    "                output_y = test_y_ls\n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            # print(file_path)\n",
    "            data = pd.read_json(file_path, lines = True)\n",
    "            filter = data[data[\"label\"] != -1]\n",
    "            filter.sample(n = int(len(filter) * 0.15))\n",
    "            # # X = np.array([])\n",
    "            X = filter.apply(lambda x: extractor.process_raw_features(x), axis = 1)\n",
    "            X_ = np.stack(X)\n",
    "            Y = np.array(filter[\"label\"])\n",
    "            output_x.append(X_)\n",
    "            output_y.append(Y)\n",
    "            # output.append(X_)\n",
    "            # output.append(Y)\n",
    "            # X_total = np.concatenate(X_train_ls, axis=0)\n",
    "            # Y_total = np.concatenate(Y_train_ls, axis=0)\n",
    "            # output.append(data)\n",
    "            # break\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110000\n",
      "50000\n",
      "110000\n",
      "110000\n",
      "110000\n",
      "110000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output_y)):\n",
    "    print(len(output_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y_ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110000, 2381)\n",
      "(50000, 2381)\n",
      "(110000, 2381)\n",
      "(110000, 2381)\n",
      "(110000, 2381)\n",
      "(110000, 2381)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_x_ls)):\n",
    "    print(train_x_ls[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.5\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = np.concatenate(train_x_ls, axis=0)\n",
    "Y_total = np.concatenate(train_y_ls, axis=0)\n",
    "np.savez(\"ember_2017full_train_vectors.npz\", X_total, Y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600000, 2381), (600000,))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_total.shape, Y_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"ember_2017full_train_vectors.npz\", X_total, Y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = np.concatenate(test_x_ls, axis=0)\n",
    "Y_total = np.concatenate(test_y_ls, axis=0)\n",
    "np.savez(\"ember_2017full_test_vectors.npz\", X_total, Y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_ls = []\n",
    "# Y_train_ls = []\n",
    "# for train in train_ls:\n",
    "#     filter = filter[filter[\"label\"] != -1]\n",
    "#     # X = np.array([])\n",
    "#     extractor = ember.PEFeatureExtractor(2)\n",
    "#     X = filter.apply(lambda x: extractor.process_raw_features(x), axis = 1)\n",
    "#     X_ = np.stack(X)\n",
    "#     Y = np.array(filter[\"label\"])\n",
    "#     X_train_ls.append(X_)\n",
    "#     Y_train_ls.append(Y)\n",
    "# X_total = np.concatenate(train_ls[0::2], axis=0)\n",
    "# Y_total = np.concatenate(train_ls[1::2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"ember_subset_vectos.npz\", X_total, Y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110000, 2381)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_total = np.concatenate(ls, axis = 0)\n",
    "X_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((110000, 2381), (110000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_path = \"../../../models_backup/ember_2017full_vectors.npz\"\n",
    "data = np.load(np_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['arr_0']\n",
    "Y = data['arr_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of used features: 2381\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of used features:\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90299/93856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=16, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=True, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    # Set the number of trees to 100\n",
    "    n_estimators=100,\n",
    "    # Set the random state to 0 to ensure reproducibility\n",
    "    random_state=0,\n",
    "    # Enable the out-of-bag (OOB) score\n",
    "    oob_score = True,\n",
    "    # Set the maximum depth of the trees to 16\n",
    "    max_depth = 16)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9765454545454545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97     10000\n",
      "           1       0.98      0.98      0.98     12000\n",
      "\n",
      "    accuracy                           0.98     22000\n",
      "   macro avg       0.98      0.98      0.98     22000\n",
      "weighted avg       0.98      0.98      0.98     22000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_ember_subset.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'rf_ember_subset.joblib')\n",
    "# sel_features = X_train.columns\n",
    "# open('../models/features.pkl', 'wb').write(pickle.dumps(sel_features)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.load(models/rf_ember_subset.joblib)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ember",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
